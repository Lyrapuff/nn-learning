{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXqc0GdL6gL1My6SPGBqhy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS188vzuPC-i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "\n",
        "chars = sorted(set(''.join(words)))\n",
        "\n",
        "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "\n",
        "itos = {i: s for s, i in stoi.items()}\n",
        "\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:]:\n",
        "  w = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
        "  for ch1, ch2, ch3 in zip(w, w[1:], w[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs.append((ix1, ix2))\n",
        "    ys.append(ix3)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "7import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27).float()"
      ],
      "metadata": {
        "id": "TcHTTX7oVPMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27 * 2, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "a4vL0F16WRjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  #forawrd pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float()\n",
        "  xenc = xenc.view(-1, 27 * 2)\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "  loss = -probs[torch.arange(len(probs)), ys].log().mean()\n",
        "\n",
        "  print(loss.item())\n",
        "\n",
        "  #backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  W.data += -30 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQSjxfnVgNJT",
        "outputId": "d7974963-079f-4148-cf33-1cb402d49f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0713019371032715\n",
            "2.0711755752563477\n",
            "2.0710506439208984\n",
            "2.0709264278411865\n",
            "2.070803642272949\n",
            "2.0706818103790283\n",
            "2.070561408996582\n",
            "2.0704424381256104\n",
            "2.070324182510376\n",
            "2.070207357406616\n",
            "2.070091724395752\n",
            "2.069976806640625\n",
            "2.0698630809783936\n",
            "2.0697505474090576\n",
            "2.069638729095459\n",
            "2.069528341293335\n",
            "2.0694189071655273\n",
            "2.069310188293457\n",
            "2.0692026615142822\n",
            "2.069096088409424\n",
            "2.068990707397461\n",
            "2.0688858032226562\n",
            "2.068782091140747\n",
            "2.0686793327331543\n",
            "2.068577527999878\n",
            "2.068476438522339\n",
            "2.0683765411376953\n",
            "2.06827712059021\n",
            "2.06817889213562\n",
            "2.0680811405181885\n",
            "2.0679845809936523\n",
            "2.0678887367248535\n",
            "2.067793846130371\n",
            "2.067699432373047\n",
            "2.0676064491271973\n",
            "2.0675137042999268\n",
            "2.0674219131469727\n",
            "2.0673305988311768\n",
            "2.0672404766082764\n",
            "2.067150831222534\n",
            "2.0670621395111084\n",
            "2.06697416305542\n",
            "2.0668869018554688\n",
            "2.066800117492676\n",
            "2.0667145252227783\n",
            "2.066629409790039\n",
            "2.066544532775879\n",
            "2.0664608478546143\n",
            "2.066377639770508\n",
            "2.0662951469421387\n",
            "2.066213369369507\n",
            "2.066132068634033\n",
            "2.066051483154297\n",
            "2.065971612930298\n",
            "2.065892457962036\n",
            "2.0658135414123535\n",
            "2.0657358169555664\n",
            "2.0656580924987793\n",
            "2.0655815601348877\n",
            "2.065505027770996\n",
            "2.065429449081421\n",
            "2.065354585647583\n",
            "2.065279960632324\n",
            "2.0652060508728027\n",
            "2.0651330947875977\n",
            "2.0650599002838135\n",
            "2.064987897872925\n",
            "2.0649161338806152\n",
            "2.064845085144043\n",
            "2.064774513244629\n",
            "2.064704179763794\n",
            "2.064634323120117\n",
            "2.064565420150757\n",
            "2.0644967555999756\n",
            "2.0644288063049316\n",
            "2.064361333847046\n",
            "2.0642940998077393\n",
            "2.06422758102417\n",
            "2.064161539077759\n",
            "2.0640957355499268\n",
            "2.064030885696411\n",
            "2.0639660358428955\n",
            "2.063901662826538\n",
            "2.063838005065918\n",
            "2.063774824142456\n",
            "2.0637118816375732\n",
            "2.0636494159698486\n",
            "2.0635876655578613\n",
            "2.063526153564453\n",
            "2.063464879989624\n",
            "2.0634043216705322\n",
            "2.0633442401885986\n",
            "2.063284397125244\n",
            "2.0632247924804688\n",
            "2.0631659030914307\n",
            "2.063107490539551\n",
            "2.063049077987671\n",
            "2.062991142272949\n",
            "2.062934160232544\n",
            "2.0628769397735596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([[ix1], [ix2]]), num_classes=27).float()\n",
        "    xenc = xenc.view(-1, 27 * 2)\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    ix1 = ix2\n",
        "\n",
        "    ix2 = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  \n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwxIsUp3hGgy",
        "outputId": "2df8690a-2d0b-4a5c-e7bf-7f4ee5340590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "budhisha.\n",
            "ay.\n",
            "nadfinn.\n",
            "jmuthanickiyn.\n",
            "cor.\n",
            "aryeshaumiylielyna.\n",
            "afi.\n"
          ]
        }
      ]
    }
  ]
}